@article{Sweedler2015,
author = {Sweedler, Jonathan V.},
doi = {10.1021/acs.analchem.5b04300},
file = {:Users/U8004755/Dropbox/Work/Reproducible Research/References/acs{\%}2Eanalchem{\%}2E5b04300.pdf:pdf},
issn = {15206882},
journal = {Anal. Chem.},
mendeley-groups = {Reproducible Research},
number = {23},
pages = {11603--11604},
title = {{Striving for Reproducible Science}},
volume = {87},
year = {2015}
}
@article{Weissgerber2016,
author = {Weissgerber, Tracey L and Garovic, Vesna D and Winham, Stacey J and Milic, Natasa M and Prager, Eric M},
doi = {10.1002/jnr.23785},
file = {:Users/U8004755/Dropbox/Work/Reproducible Research/References/jnr23785.pdf$\backslash$;jsessionid=116999E636840793B33ADF83280C5C68.f01t04.pdf:pdf},
issn = {03604012},
journal = {J. Neurosci. Res.},
mendeley-groups = {Reproducible Research},
pages = {1--6},
title = {{Transparent reporting for reproducible science}},
url = {http://doi.wiley.com/10.1002/jnr.23785},
volume = {00},
year = {2016}
}
@article{Ioannidis2015,
abstract = {As the scientific enterprise has grown in size and diversity, we need empirical evidence on the research process to test and apply interventions that make it more efficient and its results more reliable. Meta-research is an evolving scientific discipline that aims to evaluate and improve research practices. It includes thematic areas of methods, reporting, reproducibility, evaluation, and incentives (how to do, report, verify, correct, and reward science). Much work is already done in this growing field, but efforts to-date are fragmented. We provide a map of ongoing efforts and discuss plans for connecting the multiple meta-research efforts across science worldwide.},
author = {Ioannidis, John P A and Fanelli, Daniele and Dunne, Debbie Drake and Goodman, Steven N.},
doi = {10.1371/journal.pbio.1002264},
file = {:Users/U8004755/Dropbox/Work/Reproducible Research/References/journal.pbio.1002264.pdf:pdf},
issn = {15457885},
journal = {PLoS Biol.},
mendeley-groups = {Reproducible Research},
number = {10},
pages = {1--7},
pmid = {26431313},
title = {{Meta-research: Evaluation and Improvement of Research Methods and Practices}},
url = {http://dx.doi.org/10.1371/journal.pbio.1002264},
volume = {13},
year = {2015}
}
@article{Iqbal2016,
abstract = {There is a growing movement to encourage reproducibility and transparency practices in the scientific community, including public access to raw data and protocols, the conduct of replication studies, systematic integration of evidence in systematic reviews, and the documentation of funding and potential conflicts of interest. In this survey, we assessed the current status of reproducibility and transparency addressing these indicators in a random sample of 441 biomedical journal articles published in 2000-2014. Only one study provided a full protocol and none made all raw data directly available. Replication studies were rare (n = 4), and only 16 studies had their data included in a subsequent systematic review or meta-analysis. The majority of studies did not mention anything about funding or conflicts of interest. The percentage of articles with no statement of conflict decreased substantially between 2000 and 2014 (94.4{\%} in 2000 to 34.6{\%} in 2014); the percentage of articles reporting statements of conflicts (0{\%} in 2000, 15.4{\%} in 2014) or no conflicts (5.6{\%} in 2000, 50.0{\%} in 2014) increased. Articles published in journals in the clinical medicine category versus other fields were almost twice as likely to not include any information on funding and to have private funding. This study provides baseline data to compare future progress in improving these indicators in the scientific literature.},
author = {Iqbal, Shareen A. and Wallach, Joshua D. and Khoury, Muin J. and Schully, Sheri D. and Ioannidis, John P A},
doi = {10.1371/journal.pbio.1002333},
file = {:Users/U8004755/Dropbox/Work/Reproducible Research/References/journal.pbio.1002333.pdf:pdf},
isbn = {1545-7885 (Electronic)
1544-9173 (Linking)},
issn = {15457885},
journal = {PLoS Biol.},
mendeley-groups = {Reproducible Research},
number = {1},
pages = {1--13},
pmid = {26726926},
title = {{Reproducible Research Practices and Transparency across the Biomedical Literature}},
url = {http://dx.doi.org/10.1371/journal.pbio.1002333},
volume = {14},
year = {2016}
}
@article{Ioannidis2014,
abstract = {{\textless}sec{\textgreater} {\textless}title{\textgreater}{\textless}/title{\textgreater} {\textless}p{\textgreater}In a 2005 paper that has been accessed more than a million times, John Ioannidis explained why most published research findings were false. Here he revisits the topic, this time to address how to improve matters.{\textless}/p{\textgreater} {\textless}p{\textgreater}{\textless}italic{\textgreater}Please see later in the article for the Editors' Summary{\textless}/italic{\textgreater}{\textless}/p{\textgreater} {\textless}/sec{\textgreater}},
author = {Ioannidis, John P A},
doi = {10.1371/journal.pmed.1001747},
file = {:Users/U8004755/Dropbox/Work/Reproducible Research/References/journal.pmed.1001747.pdf:pdf},
isbn = {1549-1277},
issn = {15491676},
journal = {PLoS Med.},
mendeley-groups = {Reproducible Research},
number = {10},
pmid = {25334033},
title = {{How to Make More Published Research True}},
volume = {11},
year = {2014}
}
@article{Stodden2013,
abstract = {Journal policy on research data and code availability is an important part of the ongoing shift toward publishing reproducible computational science. This article extends the literature by studying journal data sharing policies by year (for both 2011 and 2012) for a referent set of 170 journals. We make a further contribution by evaluating code sharing policies, supplemental materials policies, and open access status for these 170 journals for each of 2011 and 2012. We build a predictive model of open data and code policy adoption as a function of impact factor and publisher and find higher impact journals more likely to have open data and code policies and scientific societies more likely to have open data and code policies than commercial publishers. We also find open data policies tend to lead open code policies, and we find no relationship between open data and code policies and either supplemental material policies or open access journal status. Of the journals in this study, 38{\%} had a data policy, 22{\%} had a code policy, and 66{\%} had a supplemental materials policy as of June 2012. This reflects a striking one year increase of 16{\%} in the number of data policies, a 30{\%} increase in code policies, and a 7{\%} increase in the number of supplemental materials policies. We introduce a new dataset to the community that categorizes data and code sharing, supplemental materials, and open access policies in 2011 and 2012 for these 170 journals.},
author = {Stodden, Victoria and Guo, Peixuan and Ma, Zhaokun},
doi = {10.1371/journal.pone.0067111},
file = {:Users/U8004755/Dropbox/Work/Reproducible Research/References/journal.pone.0067111.pdf:pdf},
isbn = {19326203 (ISSN)},
issn = {19326203},
journal = {PLoS One},
mendeley-groups = {Reproducible Research},
number = {6},
pages = {2--9},
pmid = {23805293},
title = {{Toward Reproducible Computational Research: An Empirical Analysis of Data and Code Policy Adoption by Journals}},
volume = {8},
year = {2013}
}
@article{Brunsdon2015,
author = {Brunsdon, C.},
doi = {10.1177/0309132515599625},
file = {:Users/U8004755/Dropbox/Work/Reproducible Research/References/Prog Hum Geogr-2015-Brunsdon-0309132515599625.pdf:pdf},
isbn = {0309132515599},
issn = {0309-1325},
journal = {Prog. Hum. Geogr.},
keywords = {a great deal of,big data,computational paradigm,geocomputation,i reproducibility in research,practical quantitative work in,programming,reproducibility},
mendeley-groups = {Reproducible Research},
title = {{Quantitative methods I: Reproducible research and quantitative geography}},
url = {http://phg.sagepub.com/cgi/doi/10.1177/0309132515599625},
year = {2015}
}
@article{Fitzjohn2014,
author = {Fitzjohn, Rich and Pennell, Matt and Zanne, Amy and Cornwell, Will},
file = {:Users/U8004755/Dropbox/Work/Reproducible Research/References/Reproducible research is still a challenge.pdf:pdf},
journal = {ROpensci.org},
keywords = {OPENSCIENCE,R,active papers,manifeste,open science,replication,tools},
mendeley-groups = {Reproducible Research},
title = {{Reproducible research is still a challenge}},
url = {http://ropensci.org/blog/2014/06/09/reproducibility/},
volume = {2014},
year = {2014}
}
@article{Fidler2013,
author = {Fidler, Fiona and Gordon, Ascelin},
file = {:Users/U8004755/Dropbox/Work/Reproducible Research/References/Science is in a reproducibility crisis â€“ how do we resolve it?.pdf:pdf},
journal = {Phys.org},
keywords = {OPENSCIENCE,blog,open science,replication,scandal},
mendeley-groups = {Reproducible Research},
title = {{Science is in a reproducibility crisis: How do we resolve it?}},
url = {http://phys.org/news/2013-09-science-crisis.html?utm{\_}content=bufferde383{\{}{\&}{\}}utm{\_}source=buffer{\{}{\&}{\}}utm{\_}medium=twitter{\{}{\&}{\}}utm{\_}campaign=Buffer{\{}{\#}{\}}ajTabs},
year = {2013}
}
@article{Madden2015,
abstract = {The P value (significance level) is possibly the mostly widely used, and also misused, quantity in data analysis. P has been heavily criticized on philosophical and theoretical grounds, especially from a Bayesian perspective. In contrast, a properly interpreted P has been strongly defended as a measure of evidence against the null hypothesis, H0. We discuss the meaning of P and null-hypothesis statistical testing, and present some key arguments concerning their use. P is the probability of observing data as extreme as, or more extreme than, the data actually observed, conditional on H0 being true. However, P is often mistakenly equated with the posterior probability that H0 is true conditional on the data, which can lead to exaggerated claims about the effect of a treatment, experimental factor or interaction. Fortunately, a lower bound for the posterior probability of H0 can be approximated using P and the prior probability that H0 is true. When one is completely uncertain about the truth of H0 before an experiment (i.e., when the prior probability of H0 is 0.5), the posterior probability of H0 is much higher than P, which means that one needs P values lower than typically accepted for statistical significance (e.g., P = 0.05) for strong evidence against H0. When properly interpreted, we support the continued use of P as one component of a data analysis that emphasizes data visualization and estimation of effect sizes (treatment effects).},
author = {Madden, L V and Shah, D a and Esker, P D},
doi = {10.1094/PHYTO-07-15-0165-LE},
file = {:Users/U8004755/Downloads/phyto-07-15-0165-le.pdf:pdf},
issn = {0031-949X},
journal = {Phytopathology},
mendeley-groups = {Reproducible Research},
pages = {1400--1407},
pmid = {26325004},
title = {{Does the P Value Have a Future in Plant Pathology?}},
volume = {105},
year = {2015}
}
