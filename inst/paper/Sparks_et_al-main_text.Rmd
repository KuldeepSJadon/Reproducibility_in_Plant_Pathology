---
title: "Status and Best Practices for Reproducible Research In Plant Pathology"
author: "A. H. Sparks, E. M. Del Ponte, S. Everhart, N. J. Grünwald, and Z. Foster"
date: 'Last update: `r Sys.Date()`'
output:
  html_document:
    css: my-style.css
    theme: flatly
    toc: true
    toc_float: 
     collapsed: true
     smooth_scroll: true
  pdf_document: default
  word_document:
    reference_docx: Phytopathology_Style_Reference.docx
csl: phytopathology.csl
bibliography: bibliography.bib
always_allow_html: yes
---

<!-- 
To render all formats:
rmarkdown::render('What Does Reproducible Research Mean for Plant Pathology.Rmd', output_format = 'all')
-->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
First author: Centre for Crop Health, University of Southern Queensland, Toowoomba, Qld 4350, Australia; second author: Departamento de Fitopatologia, Universidade Federal de Viçosa, Viçosa, MG, Brasil; third and fourth authors: Horticultural Crops Research Laboratory, USDA Agricultural Research Service, Corvallis, OR 97330, USA 

Accepted for publication: 

# Abstract

Reproducible research practices have been highlighted extensively during the last ten years in many fields of study as essential standards needed to promote transparency and replication of scientific results. In fact, scientific claims can only be evaluated based on how protocols, materials, equipment and methods were described; data were collected and prepared; and analyses conducted. Sharing of data and computational code are central for current scholarly dissemination and communication, but in many fields, including Plant Pathology, adoption of these practices has been slow. We randomly selected 200 articles published from 2012 to 2016 across 21 journals representative of the pathology discipline, and assigned them scores reflecting reproducibility. We found that.. Protocols specific to plant pathology and open source tools for producing reproducible work and analysis is proposed to promote reproducible practices among plant pathologists.


# Main text

## Introductory

Modern plant pathological research has many facets given the array of disciplines and sub-disciplines currently involved. Collectively, they contribute to increase our basic and applied knowledge on several aspects of pathogen biology and disease development to ultimately improve management. Scientific research in the field vary from purely observational/descriptive nature to inferential based on experimental or simulation-derived data sets. Whatever the case, research findings are verifiable based on how much of the research materials, processes and outcomes are made available, beyond what is reported in the scientific article. These include biological materials (strains), nucleic/protein sequences, experimental and simulated raw data annotations, drawing and photographs, statistical analysis codes, among other data.


##3 Reproducible research

Reproducibility in scientific research has once again been highlighted recently [@Nature_Editorial_2016; @Baker2016a] as an important issue. Patil et al. [-@Patil066803] have provided several definitions to clarify the concepts surrounding reproducibility. For the purposes of this paper we follow the definitions as given by Patil et al. [-@Patil066803].



## A general workflow

A general workflow for producing academic research involves clearly defining a research question, obtaining data for testing the hypothesis, summarizing/analyzing and presenting data and results, and writing the manuscript. Here we defined three levels of reproducibility which are also related with the evolution of computational methods and reproducible practices (Fig. 1).

A first level of reproducibility involves making available research materials such as strains and/or nucleic acid sequences in public collection and citations for methods used. A second level involves providing raw data and codes as binary files (PDF or other non-text file) in supplemental materials which do not allow prompt access to the data and running the codes because of use of expensive commercial software or a pay-wall. A highest level includes efforts to annotate structured raw data and fully document the analysis using open source code which are deposited in public repositories and can be run more easily following download of data and codes. The first level as reported is an essential step that is not substituted by the other practices and eventually researchers fail to provide sufficient description or correct citations. In the next section we present standards and tools that can be used to ensure reproducibility (Figure 1).

```{r echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
library(DiagrammeR)
library(DiagrammeRsvg)
library(rsvg)

p <- export_svg(grViz(
  "
  digraph Fig1 {
  
  graph [fontsize = 8, nodesep=0.5]
  
  node [shape = box, style = filled, fillcolor = grey99, width = 1.2,fontname = Helvetica]
  Question;  Methodology;  Data;  Analysis;  Manuscript;
  
  node [shape = box, style = filled, fillcolor = grey90, width = 1.2,fontname = Helvetica]
  Description; Availability; Citation
  
  node [shape = box, style = filled, fillcolor = grey80, width = 1.2]
  Binary_Code; Binary_File; Supplement
  
  node [shape = box, style = filled, fillcolor = grey70, width = 1.2]
  Source_Code;  Data_File; Pub_Repository;
  
  Question->Methodology->Data->Analysis
  Analysis->Manuscript
  Methodology->Description
  Methodology->Citation
  Methodology->Availability
  Manuscript->Supplement
  Data->Data_File->Pub_Repository
  Analysis->Binary_Code->Supplement
  Analysis->Source_Code->Pub_Repository
  Data->Binary_File->Supplement
  }
  ",
  width = 1000,
  height = 750
))

rsvg_pdf(charToRaw(p), "Figure 1.pdf")
```

### Methods

- Citation of methods, software, packages, etc.
- deposit and annotate biological materials
- provide full description for equipments, etc.
- rOpenSci Reproducible Research: http://ropensci.github.io/reproducibility-guide/sections/introduction/

### Data

- Data formatting (flat files; use Comma Chameleon, Table Tool, others?)
- Data annotation
- Data storage (don't edit raw data files; use file permissions to prevent changes to raw data files, use data bases where possible and appropriate; etc.)

### Source code

- The problem of commercial software and mouse-based routines
- Why to avoid binary files as supplements?
- Writing and documenting using open source software
- Availability in public repositories

### Repository
- Using GitHub for code (and small data?)
- Using Figshare or Zenodo vs a lab website (DOIs, other reasons)
- Or using, most ideally, a library or other proper long-term data archival service



## Status in Plant Pathology

* Madden et al. [-@Madden2015] supply an *e-**X**tra*\* with reproducible examples
for readers.
* Duku et al. [-@Duku2016] provide models, data and code, (http://adamhsparks.github.io/MICCORDEA/) necessary to
replicate the entire study modelling the effects of climate change on rice
bacterial blight and rice leaf blast in Tanzania.
* Sparks et al. [-@Sparks2011; -@Sparks2014] provide models, data and code, (http://adamhsparks.github.io/Global-Late-Blight-MetaModelling/)
necessary to replicate model development and the subsequent the study on the effects of climate change on potato late blight.
* Del Ponte provides data and a reproducible report that explain in details all steps of the analysis and the R codes for conducting a meta-analysis for assessing heterogeneity in relationship between white mold incidence and soybean yield and between incidence and soybean tied.
* Example from Grünwald lab: 
  - paper http://apsjournals.apsnet.org/doi/full/10.1094/PHYTO-12-14-0350-FI
  - github repo https://github.com/grunwaldlab/Sudden_Oak_Death_in_Oregon_Forests
* Other examples from plant pathology providing e-Xtras or supplemental material

Twenty-one plant pathology discipline journals were selected by the authors as representations of discipline-based journals target by the plant pathology research community. Among them, both fundamental and/or applied as well as journals covering specific group of pathogens/plants or broad areas were included. Two hundred articles were randomly selected from issues published from 2012 to 2016. A list of randomly selected pages was assigned to a randomized list of the 21 journals [@Sparks2017] where the page number fell within an article for the given journal. In cases where an article was not suitable, _e.g._, a review or otherwise not related to plant pathology, the next article was selected until a suitable article was found. Notes regarding the selection of articles can be found in the file, XXXX, available in this paper's repository. The pages list was numbered from page one and went to 150. This was done since some journals restart their numbering with each issue and also ensures that the journal is more likely to have a page number corresponding to the randomly generated value. This also assumes that there is no effect or bias on reproducibility based on the time of year that an article was published, since most journals start with page number one at the beginning of the year. The list of journals was saved as a comma separated value (CSV) file and imported into R [@R2017]. 


## Discussion


## Acknowledgments


## Literature cited

