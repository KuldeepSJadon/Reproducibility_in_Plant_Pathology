---
title: "Status and Best Practices for Reproducible Research In Plant Pathology"
author: "A. H. Sparks, E. M. Del Ponte, N. J. Grünwald, and Z. Foster"
date: 'Last update: `r Sys.Date()`'
output:
  word_document:
    keep_md: yes
    reference_docx: Phytopathology_Style_Reference.docx
  pdf_document: default
  html_document: default
csl: phytopathology.csl
bibliography: bibliography.bib
always_allow_html: yes
---

<!-- 
To render all formats:
rmarkdown::render('What Does Reproducible Research Mean for Plant Pathology.Rmd', output_format = 'all')
-->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
First author: Centre for Crop Health, University of Southern Queensland, Toowoomba, Qld 4350, Australia; second author: Departamento de Fitopatologia, Universidade Federal de Viçosa, Viçosa, MG, Brasil; third and fourth authors: Horticultural Crops Research Laboratory, USDA Agricultural Research Service, Corvallis, OR 97330, USA 

Accepted for publication: 

# Abstract

Reproducible research practices have been highlighted extensively during the last ten years in many fields of study as standard to promote transparency and replication of scientific results, a well known current issue in science. In fact, scientific claims can only be evaluated based on how: protocols, materials, equipments and methods were described; data were collected and prepared; and analyses conducted. Sharing of data and computational code are central for current scholarly dissemination and communication standadars, but in many fields, including Plant Pathology, the rate at which the researchers are engaged in this endeavour is apparently slow. We randomly selected 200 articles published from 2012 to 2016 across 21 journals representative of the pathology discipline, which were scrutinized to obtain data reflecting reproducibility. We found that.. Protocols specific to plant pathology and open source tools for producing reproducible work and analysis is proposed to promote such practice among plant pathologists.


# Main text

## Introductory

Modern plant pathological research has many facets given the array of disciplines and subdisciplines currently involved. Collectively, they contribute to increase our basic and applied knowledge on several aspects of pathogen biology and disease development to ultimately improve management. Scientific research in the field vary from purely observational/descriptive nature to inferential based on experimental or simulation-derived small/large datasets. Whenever the case, research findings are verifiable based on how much of the research materials, processes and outcomes, beyond what is reported in the scientific article, are made available. These include biological materials (strains), acid nucleic sequences, experimental and simulated raw data annotations, drawing and photographs, statistical analysis codes, among others.


##3 Reproducible research

Reproducibility and replicability in scientific research have once again been highlighted recently [@Nature_Editorial_2016; @Baker2016a] as an issue. Patil et al. [-@Patil066803] have provided several definitions to clarify the concepts surrounding reproducibility and replicability. For the purposes of this paper we follow the definitions as given by Patil et al. [-@Patil066803].



## A general workflow

A general workflow for producing academic research involves clearly defining a research question, obtaining data for testing the hypothesis, summarizing/analyzing and presenting data and results, and writing the manuscript. Here we defined three levels of reproducibility which are also related with the evolution of computational methods and reproducible practices (Fig. 1).

A first level of reproducibility involves making available research materials such as strains and/or nucleic acid sequences in public collection and citations for methods used. A second level involves providing raw data and codes as binary files (PDF or other non-text file) in supplemental materials which do not allow promptly access to the data and running the codes because of use of expensive commercial software or a paywall. A highest level includes efforts to annotate structured raw data and fully document the analysis using open source code which are deposited in public repositories and can be run more easily following download of data and codes. The first level as reported is an essential step that is not substituted by the other practices and eventually researchers fail to provide sufficient description or correct citations. In the next section we present standards and tools that can be used to ensure reproducibility (Figure 1).

```{r echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
library(DiagrammeR)
library(DiagrammeRsvg)
library(rsvg)

p <- export_svg(grViz(
  "
  digraph Fig1 {
  
  graph [fontsize = 8, nodesep=0.5]
  
  node [shape = box, style = filled, fillcolor = grey99, width = 1.2,fontname = Helvetica]
  Question;  Methodology;  Data;  Analysis;  Manuscript;
  
  node [shape = box, style = filled, fillcolor = grey90, width = 1.2,fontname = Helvetica]
  Description; Availability; Citation
  
  node [shape = box, style = filled, fillcolor = grey80, width = 1.2]
  Binary_Code; Binary_File; Supplement
  
  node [shape = box, style = filled, fillcolor = grey70, width = 1.2]
  Source_Code;  Data_File; Pub_Repository;
  
  Question->Methodology->Data->Analysis
  Analysis->Manuscript
  Methodology->Description
  Methodology->Citation
  Methodology->Availability
  Manuscript->Supplement
  Data->Data_File->Pub_Repository
  Analysis->Binary_Code->Supplement
  Analysis->Source_Code->Pub_Repository
  Data->Binary_File->Supplement
  }
  ",
  width = 1000,
  height = 750
))

rsvg_pdf(charToRaw(p), "Figure 1.pdf")
```

### Methods

- Citation of methods, software, packages, etc.
- deposit and annotate biological materials
- provide full description for equipments, etc.

### Data

- Data formatting (flat files; use Comma Chameleon, Table Tool, others?)
- Data annotation
- Data storage (don't edit raw data files; use file permissions to prevent changes to raw data files, use data bases where possible and appropriate; etc.)

### Source code

- The problem of commercial software and mouse-based routines
- Why to avoid binary files as supplements?
- Writing and documenting using open source software
- Availability in public repositories

### Repository
- Using GitHub for code (and small data?)
- Using Figshare or Zenodo vs a lab website (DOIs, other reasons)



## Status in Plant Pathology

* Madden et al. [-@Madden2015] supply an *e-**X**tra*\* with reproducible examples
for readers.
* Duku et al. [-@Duku2016] provide models, data and code, (http://adamhsparks.github.io/MICCORDEA/) necessary to
replicate the entire study modelling the effects of climate change on rice
bacterial blight and rice leaf blast in Tanzania.
* Sparks et al. [-@Sparks2011; -@Sparks2014] provide models, data and code, (http://adamhsparks.github.io/Global-Late-Blight-MetaModelling/)
necessary to replicate model development and the subsequent the study on the effects of climate change on potato late blight.
* Del Ponte provides data and a reproducible report that explain in details all steps of the analysis and the R codes for conducting a meta-analysis for assessing heterogeneity in relationship between white mold incidence and soybean yield and between incidence and soybean tied.
* Example from Grünwald lab: 
  - paper http://apsjournals.apsnet.org/doi/full/10.1094/PHYTO-12-14-0350-FI
  - github repo https://github.com/grunwaldlab/Sudden_Oak_Death_in_Oregon_Forests
* Other examples from plant pathology providing e-Xtras or supplemental material


Twenty-one plant pathology discipline journals were selected by the authors as representations of discipline-based journals target by the plant pathology research community. Among them, both fundamental and/or applied as well as journals covering specific group of pathogens/plants or broad areas were included. Two hundred articles were randomly selected from issues published from 2012 to 2016. A list of randomly selected pages was assigned to a randomised list of the 21 journals [@Sparks2017] where the page number fell within an article for the given journal. In cases where an article was not suitable, _e.g._, a review or otherwise not related to plant pathology, the next article was selected until a suitable article was found. Notes regarding the selection of articles can be found in the file, XXXX, available in this paper's repository. The pages list was numbered from page one and went to 150. This was done since some journals restart their numbering with each issue and also ensures that the journal is more likely to have a page number corresponding to the randomly generated value. This also assumes that there is no effect or bias on reproducibility based on the time of year that an article was published, since most journals start with page number one at the beginning of the year. The list of journals was saved as a comma separated value (CSV) file and imported into R [@R2017]. 


## Discussion


## Acknowledgments


## Literature cited

